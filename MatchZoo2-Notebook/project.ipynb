{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Dataset\n",
    "MatchZoo expect a list of *Quintuple* as training data. The corresponded columns are `(text_left_id, text_right_id, text_left, text_right, label)`. For Information Retrieval task, `text_left` is referred as `query`, and `text_right` is document.\n",
    "\n",
    "For the test case, MatchZoo expect a list of *Quadruple* (we do not need labels) as input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MatchZoo expect a list of *Quintuple* as training data:\n",
    "\n",
    "```python\n",
    "train = [('qid0', 'did0', 'query 0', 'document 0', 'label 0'),\n",
    "         ('qid0', 'did1', 'query 0', 'document 1', 'label 1'),\n",
    "          ...,\n",
    "         ('qid1', 'did2', 'query 1', 'document 2', 'label 3')]\n",
    "```\n",
    "\n",
    "The corresponded columns are `(text_left_id, text_right_id, text_left, text_right, label)`. For Information Retrieval task, *text_left* is referred as *query*, and *text_right* is document.\n",
    "\n",
    "For the test case, MatchZoo expect a list of *Quadruple* (we do not need labels) as input:\n",
    "\n",
    "```python\n",
    "test = [('qid9', 'did5', 'query 9', 'document 5'),\n",
    "         ...,\n",
    "        ('qid2', 'did7', 'query 2', 'document 7')]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T03:28:21.428869Z",
     "start_time": "2018-11-07T03:28:21.364345Z"
    }
   },
   "outputs": [],
   "source": [
    "def read_data(path, stage):\n",
    "    def scan_file():\n",
    "        with open(path) as in_file:\n",
    "            next(in_file)  # skip header\n",
    "            for l in in_file:\n",
    "                yield l.strip().split('\\t')\n",
    "    if stage == 'train':\n",
    "        return [(qid, did, q, d, label) for qid, did, q, d, label in scan_file()]\n",
    "    elif stage == 'predict':\n",
    "        return [(elem[0], elem[1], elem[2], elem[3]) for elem in scan_file()]\n",
    "\n",
    "train = read_data('data/matchzoo_input.txt', stage='train')\n",
    "#predict  = read_data('data/matchzoo_predict.txt', stage='predict')\n",
    "rank = read_data('data/matchzoo_rank.txt', stage='predict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T03:28:21.433757Z",
     "start_time": "2018-11-07T03:28:21.430544Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('350', 'FT934-11789', 'Health and Computer Terminals', \"11 18 20,000 29 70 93 931029 _an a a a a a a a a a a action action after against against agency agree also although an an and and and and and and and and and and and anything appeal are arms as as as as as as as ascribe at at at authentic award be be because because been being being bernard between books both britain brought but by by by by by by care case case case case cast causal cause charter claim claim claim clerical colleague come comp company company computer computer concept condition condition condition conditions conditions confidence confuse considering continue correspondent costs could could country court court court court court court court criticise damages damages damages describe disappointed dismiss disorder dj2dcad8ft doubt down due ec editor elbow emergence emotional employ employee employer even exist expert factor felt financial first for for for for former ft future future gbz go greatest had had hand he he he he high his his his his his his his his his his holding hundred in in in in in in in in in individual industry injure injury injury insist into involve involve it it it it it its its its john john journalist journalist judge judge judge judge judge judgment judgment judgment keyboard keyboard kingdom lack late law legal lie likely limb limb london manual mason matthews meaningless medical medical medical medical medical medical more most mr mr mr mr mr mr mughal mughal mughal's mughal's national news news newspaper no no no no not not nuj oct of of of of of of of of of offer office on only only or ordered other out outcome p9211 page page pain pattern pay payment peter physical physiotherapy place pound problem problem producer prosser prosser prove rafiq rafiq recent recent recognise recognise relationship repetition responsible reuter reuter reuter reuter root rsi rsi rsi rsi rsi rsi rsi rsi rule ruling ruling ruling said said said said said said said said said secretary series serve settle several shoulder sleep society solicitor some some specialist specific staff state strain sub substantial such suffer symptom symptom tablet telecom tennis tenosynoviti term text textbook than that that that the the the the the the the the the the the the the the the the the the the the the the these those thrown times to to to to to to to to took took turkey turn type uncertainty union union union united unlike upper upper use use very victimise was was was was was was was was was was watch welcome well were were which who with with work work work worker worker working would yesterday yesterday yesterday's \", '1')\n",
      "('301', 'LA101589-0174', 'International Organized Crime', \"1 12 121034 135 14 15 1987 1988 1989 2 23 3 3 3.3 300 350,000 37 38 44 50 57 6 6 7,000 80 841 a a a a a a a a a a a a a a a a a a a.m about absentia absentia according accused accused accused action acts administration administration against against agency ago allied also also america amid among an an ana and and and and and and and and and and and and and and and and and and and and announce anonymous another another antonacci anyone are are arrest arrest arrest arrico as as as as as as at atlanta atlanta attorney atty aug august authority authority authority await background barco barco be be be be be been before believe bendeck bendeck bendeck bendeck's bernardo big bodyguard bogota bogota bogota bogota bogota bogota bogota bogota bomb bring broadcast broadcast brought brought bureau but by by by by by by by by call call caller canada canada canada caribbean carlini carlini carlini carlos cartagena cartagena cartagena cartel cartel cartel cartel cartel cartel cartel cartel cartel cartel charge charge charge charge charge charges.sh chief citizen city cocaine cocaine cocaine cocaine cocaine cocaine cocaine cocaine cocaine cocaine coincide colombia colombia colombia colombia colombia colombia colombia colombia colombia colombia colombia colombia colombia colombia colombia colombia colombia colombia's colombia's colombia's column commend conspiracy conspiracy continue continue continue continue continue control convict convict convict cordoba country country's court court crack cracked damage days de deliver department department's deport deport describe describe desk detroit detroit detroit development dick diligence directly director director distribute distribute don down down down drug drug drug drug drug drug drug drug drug drug drug drug drug drug drug drug drug drug edition eduardo effort el el el employee employee employee enforce enforce enter escalate escape espectador espectador even example extradite extradite extradite extradite extradite extradite extradite face face face face federal federal federal federal figure figure figures figures finance first first five fla fla flamboyant florida flown flown for for for for for for foreign four four four fourth friday friday from from front front gen gen government government government government group guerrilla gunmen gunmen had had has have he he he he he he he he he head him him him his his his his home home home houle i identify identify immediately immigrant import import import important in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in in infobox intent intent international intimidation into involve is is is italy its jacksonville jail jail journalist journalist journalist judge july justice justice kill kill kill kill killer killing killing killing kingpin kingpin known la last last late latest launder leading leave lehder life like link lives living local lord magazine magistrate marijuana marquez marshal martinez martinez martinez maza meanwhile medellin medellin medellin medellin medellin medellin medellin medellin medellin medellin member metro miami miami miguel mile monday money monteria month more more most most most motorcycle much murder narco news news newspaper newspaper newspaper newspaper's night no north northern not notorious number october of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of of officer offices official olivella on on on on on on on on on on on on on on on once one one one operate opponent orlando orlando other over over over page part part partner passionate pay pelaez pelaez pelaez pelaez pelaez pelaez people people person pete player plus police police port possess possess possess possibly pound praise prensa president prison prisoner prisoner program prosecutor radio ranch related relations report report report reporter reputed resort retaliatory richard ring riva roberto rodriguez roldan romero said said saturday saturday saturday schedule sell sentence sentence sentence sept sept seriously setting shannon shot significant since slain slain smuggle smuggle so son staff state state state states states states states states still sunday suspect swoop tamayo tamayo tamayo terrorism terrorist than than that that that the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the the their them they they they third thornburgh thornburgh threat threat threat threaten three three tiempo times to to to to to to to to to to to to to to to to to to to to to to to to to to to to ton ton ton top town traffick trafficker trafficker trafficker trafficker transfer treasurer trial trial trial troops try tuesday tuesday turn turn turning two two two two two u.s u.s u.s u.s u.s u.s u.s united united united united united unless varga victim vigilio violence want want war war was was was was was was was was was was was was was was was washington week went were were where which who who whose will will william with with with with words world world would would writer years years years \")\n"
     ]
    }
   ],
   "source": [
    "print(train[0])\n",
    "#print(predict[0])\n",
    "print(rank[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T03:28:45.196770Z",
     "start_time": "2018-11-07T03:28:21.435916Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start building vocabulary & fitting parameters.\n",
      "100it [00:00, 3365.84it/s]\n",
      "11011it [01:53, 97.08it/s] \n",
      "Start processing input data for train stage.\n",
      "100it [00:00, 2190.72it/s]\n",
      "11011it [02:05, 88.04it/s] \n"
     ]
    }
   ],
   "source": [
    "from matchzoo import preprocessor\n",
    "dssm_preprocessor = preprocessor.DSSMPreprocessor()\n",
    "datapack_train = dssm_preprocessor.fit_transform(train, stage='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T03:28:45.274981Z",
     "start_time": "2018-11-07T03:28:45.269441Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matchzoo.datapack.DataPack"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(datapack_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T03:28:45.310431Z",
     "start_time": "2018-11-07T03:28:45.277623Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_left</th>\n",
       "      <th>length_left</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_left</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>350</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>351</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>354</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text_left  length_left\n",
       "id_left                                                                \n",
       "350      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        20813\n",
       "351      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        20813\n",
       "352      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        20813\n",
       "353      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        20813\n",
       "354      [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...        20813"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-processed records including index and processed text to store `text_left` and `id_left`\n",
    "datapack_train.left.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T03:28:45.324161Z",
     "start_time": "2018-11-07T03:28:45.312470Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_right</th>\n",
       "      <th>length_right</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id_right</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>FT934-11789</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA091090-0108</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA120789-0021</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LA031990-0076</th>\n",
       "      <td>[0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FT921-12910</th>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...</td>\n",
       "      <td>20813</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      text_right  length_right\n",
       "id_right                                                                      \n",
       "FT934-11789    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...         20813\n",
       "LA091090-0108  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...         20813\n",
       "LA120789-0021  [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...         20813\n",
       "LA031990-0076  [0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...         20813\n",
       "FT921-12910    [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, ...         20813"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-processed records including index and processed text to store `text_right` and `id_right`\n",
    "datapack_train.right.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T03:28:45.334410Z",
     "start_time": "2018-11-07T03:28:45.325976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id_left</th>\n",
       "      <th>id_right</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>350</td>\n",
       "      <td>FT934-11789</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>350</td>\n",
       "      <td>LA091090-0108</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>350</td>\n",
       "      <td>LA120789-0021</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>350</td>\n",
       "      <td>LA031990-0076</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>350</td>\n",
       "      <td>FT921-12910</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id_left       id_right label\n",
       "0     350    FT934-11789     1\n",
       "1     350  LA091090-0108     1\n",
       "2     350  LA120789-0021     1\n",
       "3     350  LA031990-0076     1\n",
       "4     350    FT921-12910     1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pre-processed records including index and index mapping `id_left` and `id_right`\n",
    "datapack_train.relation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T03:28:45.340212Z",
     "start_time": "2018-11-07T03:28:45.336222Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['term_index', 'input_shapes'])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# other information stored during the pre-processing process\n",
    "datapack_train.context.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T03:28:45.345644Z",
     "start_time": "2018-11-07T03:28:45.342052Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20812"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# vocabulary size\n",
    "len(datapack_train.context['term_index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T03:28:45.351528Z",
     "start_time": "2018-11-07T03:28:45.347636Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(20813,), (20813,)]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# since DSSM models' input shapes are dynamic\n",
    "# (depend on the generated tri-letters)\n",
    "# so we have to calculate shapes during the pre-processing process\n",
    "datapack_train.context['input_shapes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T03:28:45.358159Z",
     "start_time": "2018-11-07T03:28:45.353603Z"
    }
   },
   "outputs": [],
   "source": [
    "from matchzoo import generators\n",
    "from matchzoo import tasks\n",
    "generator_train = generators.PointGenerator(\n",
    "    inputs=datapack_train, task=tasks.Ranking(), batch_size=64, stage='train')\n",
    "#generator_predict = generators.PointGenerator(\n",
    "#   inputs=datapack_predict, task=tasks.Ranking(), batch_size=64, stage='predict')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T03:28:45.362989Z",
     "start_time": "2018-11-07T03:28:45.359992Z"
    }
   },
   "outputs": [],
   "source": [
    "from matchzoo import models, load_model\n",
    "from matchzoo import losses\n",
    "from matchzoo import tasks\n",
    "from matchzoo import metrics\n",
    "dssm_model = models.DSSMModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T03:28:45.367297Z",
     "start_time": "2018-11-07T03:28:45.364784Z"
    }
   },
   "outputs": [],
   "source": [
    "# handle dynamic input shapes of DSSM\n",
    "input_shapes = datapack_train.context['input_shapes']\n",
    "dssm_model.params['input_shapes'] = input_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T03:28:45.374542Z",
     "start_time": "2018-11-07T03:28:45.369113Z"
    }
   },
   "outputs": [],
   "source": [
    "dssm_model.params['task'] = tasks.Ranking()\n",
    "dssm_model.params['task'].metrics = ['mae', 'map']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T03:28:45.379999Z",
     "start_time": "2018-11-07T03:28:45.376449Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name                          DSSMModel\n",
      "model_class                   <class 'matchzoo.models.dssm_model.DSSMModel'>\n",
      "input_shapes                  [(20813,), (20813,)]\n",
      "task                          <matchzoo.tasks.ranking.Ranking object at 0x210694f28>\n",
      "optimizer                     adam\n",
      "w_initializer                 glorot_normal\n",
      "b_initializer                 zeros\n",
      "dim_fan_out                   128\n",
      "dim_hidden                    300\n",
      "activation_hidden             tanh\n",
      "num_hidden_layers             2\n"
     ]
    }
   ],
   "source": [
    "dssm_model.guess_and_fill_missing_params()\n",
    "print(dssm_model.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T03:28:57.633873Z",
     "start_time": "2018-11-07T03:28:45.382247Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 125s 125ms/step - loss: 0.1149 - mean_absolute_error: 0.2386\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 135s 135ms/step - loss: 0.0781 - mean_absolute_error: 0.1715\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 127s 127ms/step - loss: 0.0714 - mean_absolute_error: 0.1561\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 111s 111ms/step - loss: 0.0688 - mean_absolute_error: 0.1519\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 112s 112ms/step - loss: 0.0718 - mean_absolute_error: 0.1574\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.0597 - mean_absolute_error: 0.1332\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 109s 109ms/step - loss: 0.0641 - mean_absolute_error: 0.1398\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 110s 110ms/step - loss: 0.0590 - mean_absolute_error: 0.1275\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 106s 106ms/step - loss: 0.0628 - mean_absolute_error: 0.1351\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 103s 103ms/step - loss: 0.0679 - mean_absolute_error: 0.1384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x157722be0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dssm_model.build()\n",
    "dssm_model.compile()\n",
    "dssm_model.fit_generator(generator_train, steps_per_epoch=1000, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T03:28:57.866684Z",
     "start_time": "2018-11-07T03:28:57.635679Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "64/64 [==============================] - 1s 11ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'loss': 0.03034413605928421,\n",
       " 'mean_absolute_error': 0.09994634240865707,\n",
       " 'mean_average_precision(0)': 0.3829787234042553}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = generator_train[0]\n",
    "dssm_model.evaluate(X, Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start processing input data for predict stage.\n",
      "1it [00:00, 139.94it/s]\n",
      "199it [00:06, 27.00it/s]\n"
     ]
    }
   ],
   "source": [
    "global topscore, kthscore \n",
    "datapack_rank = dssm_preprocessor.fit_transform(rank, stage='predict')\n",
    "generator_rank = generators.PointGenerator(\n",
    "    inputs=datapack_rank, task=tasks.Ranking(), batch_size=len(rank), stage='predict')\n",
    "X_rank, _ = generator_rank[0]\n",
    "k = 10\n",
    "ranking = dssm_model.predict(X_rank)\n",
    "rank_list = [r[0] for r in ranking]\n",
    "rank_list.sort(reverse=True)\n",
    "topscore = rank_list[0]\n",
    "kthscore = rank_list[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "199\n",
      "199\n"
     ]
    }
   ],
   "source": [
    "print(len(rank))\n",
    "print(len(ranking))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"results.txt\",\"w\") as f:\n",
    "    i = 0\n",
    "    for r in rank:\n",
    "        f.write(str(r[1])+\" \"+str(ranking[i][0])+\"\\n\")\n",
    "        i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def predict_proba(doc_text):\n",
    "    predict_data = list()\n",
    "    count = 1\n",
    "    did_list = list()\n",
    "    for doc in doc_text:\n",
    "        did_list.append(did + \"_PRED_\"+str(count))\n",
    "        predict_data.append((qid, did + \"_PRED_\"+ str(count), query, doc))\n",
    "        count += 1\n",
    "        \n",
    "    datapack_predict = dssm_preprocessor.fit_transform(predict_data, stage='predict')\n",
    "    generator_predict = generators.PointGenerator(\n",
    "        inputs=datapack_predict, task=tasks.Ranking(), batch_size=len(doc_text), stage='predict')\n",
    "    X_predict, _ = generator_predict[0]\n",
    "    \n",
    "    pred = dssm_model.predict(X_predict)\n",
    "    pred_list = [p[0] for p in pred]\n",
    "    pdoclist = list(zip(did_list, pred_list))\n",
    "#     pdoclist.sort(key=lambda x: x[1], reverse = True)\n",
    "    \n",
    "#     k = len(doc_text) // 10\n",
    "#     topscore = pdoclist[0][1]\n",
    "#     kscore = pdoclist[k][1]\n",
    "    \n",
    "    newdoclist = list()\n",
    "    for i in range(len(pdoclist)):\n",
    "        if pdoclist[i][1] > kthscore:\n",
    "            newdoclist.append((pdoclist[i][0], 1))\n",
    "        else:\n",
    "            newdoclist.append((pdoclist[i][0],0))\n",
    "            \n",
    "#     newdoclist.sort(key=lambda x:x[0])\n",
    "    prob = [(1 - elem[1], elem[1]) for elem in newdoclist]\n",
    "#     print(len(prob))   \n",
    "#     print(prob)\n",
    "    return np.array(prob)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lime Initialization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Start processing input data for predict stage.\n",
      "1it [00:00, 397.41it/s]\n",
      "5000it [00:13, 357.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: Health and Computer Terminals\n",
      "Class: 1\n",
      "[('union', -0.013153165917992123), ('yesterday', -0.011487588702034954), ('lie', 0.008016270926718397), ('claim', 0.0064727784825321264), ('to', 0.005746670594325541), ('costs', 0.005370372725414624), ('rule', 0.002767510543325756), ('rafiq', 0.002080211659524188), ('specialist', 0.0020101993505908995), ('employer', 0.0017860522267690092)]\n",
      "-------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2899e2a28fb1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;34m(\u001b[0m\u001b[0mqid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdocument_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mexplainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLimeTextExplainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"irrelevant\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"relevant\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_expression\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mexp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexplainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexplain_instance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocument_text\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_proba\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Query:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Class:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/lime/lime_text.py\u001b[0m in \u001b[0;36mexplain_instance\u001b[0;34m(self, text_instance, classifier_fn, labels, top_labels, num_features, num_samples, distance_metric, model_regressor)\u001b[0m\n\u001b[1;32m    388\u001b[0m         data, yss, distances = self.__data_labels_distances(\n\u001b[1;32m    389\u001b[0m             \u001b[0mindexed_string\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclassifier_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m             distance_metric=distance_metric)\n\u001b[0m\u001b[1;32m    391\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclass_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/lime/lime_text.py\u001b[0m in \u001b[0;36m__data_labels_distances\u001b[0;34m(self, indexed_string, classifier_fn, num_samples, distance_metric)\u001b[0m\n\u001b[1;32m    454\u001b[0m                                                 replace=False)\n\u001b[1;32m    455\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minactive\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 456\u001b[0;31m             \u001b[0minverse_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexed_string\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minverse_removing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minactive\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    457\u001b[0m         \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minverse_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistance_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/lime/lime_text.py\u001b[0m in \u001b[0;36minverse_removing\u001b[0;34m(self, words_to_remove)\u001b[0m\n\u001b[1;32m    170\u001b[0m         \"\"\"\n\u001b[1;32m    171\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_np\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bool'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m         \u001b[0mmask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_idxs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwords_to_remove\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m             return ''.join([self.as_list[i] if mask[i]\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/lime/lime_text.py\u001b[0m in \u001b[0;36m__get_idxs\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             return list(itertools.chain.from_iterable(\n\u001b[0;32m--> 202\u001b[0;31m                 [self.positions[z] for z in words]))\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/lime/lime_text.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbow\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             return list(itertools.chain.from_iterable(\n\u001b[0;32m--> 202\u001b[0;31m                 [self.positions[z] for z in words]))\n\u001b[0m\u001b[1;32m    203\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpositions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from lime.lime_text import LimeTextExplainer\n",
    "import re\n",
    "\n",
    "global qid, query, did\n",
    "tokenizer = lambda doc: re.compile(r\"(?u)\\b\\w\\w+\\b\").findall(doc)\n",
    "for row in train:\n",
    "    (qid, did, query, document_text, label) = row\n",
    "    explainer = LimeTextExplainer(class_names=[\"irrelevant\", \"relevant\"], split_expression=tokenizer)\n",
    "    exp = explainer.explain_instance(document_text, predict_proba, num_features=10)\n",
    "    print(\"Query:\",query)\n",
    "    print(\"Class:\",label)\n",
    "    #print(\"Document:\", document_text)\n",
    "    print(exp.as_list())\n",
    "    print(\"-------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T03:28:57.922166Z",
     "start_time": "2018-11-07T03:28:57.870349Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'generator_predict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-81773347e070>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerator_predict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdssm_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_predict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{} is predicted as {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mid_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mid_right\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'generator_predict' is not defined"
     ]
    }
   ],
   "source": [
    "X_predict, _ = generator_predict[0]\n",
    "pred = dssm_model.predict(X)\n",
    "for id_left, id_right, pred, _ in zip(X_predict.id_left, X_predict.id_right, pred, range(10)):\n",
    "    print(\"{}/{} is predicted as {}\".format(id_left, id_right, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Persistence\n",
    "\n",
    "You can persist your trained model using `model.save()` and `load_model` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T03:28:59.202799Z",
     "start_time": "2018-11-07T03:28:57.925348Z"
    }
   },
   "outputs": [],
   "source": [
    "dssm_model.save('/tmp/my_dssm_model')\n",
    "loaded_dssm_model = load_model('/tmp/my_dssm_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-11-07T03:28:59.316110Z",
     "start_time": "2018-11-07T03:28:59.204950Z"
    }
   },
   "outputs": [],
   "source": [
    "(loaded_dssm_model.predict(X) == dssm_model.predict(X)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "[Huang et al. 2013] Po-Sen Huang, Xiaodong He, Jianfeng Gao, Li Deng, Alex Acero, and Larry Heck. 2013. Learning deep structured semantic models for web search using clickthrough data. In Proc. CIKM. ACM, 2333â€“2338."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
